{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning - Data Exploration\n",
    "\n",
    "This notebook explores the Flickr8k dataset for the image captioning task. We will:\n",
    "\n",
    "1. Download and prepare the dataset\n",
    "2. Explore the images and captions\n",
    "3. Analyze the distribution of caption lengths\n",
    "4. Examine the vocabulary\n",
    "5. Visualize some sample images with their captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from data.download_flickr import download_flickr8k\n",
    "from utils.vocabulary import Vocabulary, build_vocab_from_captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare the Flickr8k dataset\n",
    "data_dir = '../data'\n",
    "paths = download_flickr8k(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the captions\n",
    "captions_path = os.path.join(paths['processed_path'], 'captions.csv')\n",
    "captions_df = pd.read_csv(captions_path)\n",
    "\n",
    "# Display the first few rows\n",
    "captions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the Images and Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique images and total captions\n",
    "unique_images = captions_df['image'].nunique()\n",
    "total_captions = len(captions_df)\n",
    "\n",
    "print(f\"Total number of images: {unique_images}\")\n",
    "print(f\"Total number of captions: {total_captions}\")\n",
    "print(f\"Average captions per image: {total_captions / unique_images:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sample of images with their captions\n",
    "# TODO: Implement the function to display images with their captions\n",
    "# This function should:\n",
    "# 1. Take a DataFrame of captions, path to images directory, and number of samples\n",
    "# 2. Get random image samples\n",
    "# 3. Create a figure with subplots\n",
    "# 4. For each image:\n",
    "#    a. Load and display the image\n",
    "#    b. Find all captions for that image\n",
    "#    c. Add captions as a formatted title\n",
    "def display_images_with_captions(captions_df, images_dir, num_samples=5):\n",
    "    # Get unique images\n",
    "    unique_image_df = captions_df.drop_duplicates(subset=['image'])\n",
    "    \n",
    "    # Your implementation here\n",
    "\n",
    "# Display some sample images with their captions\n",
    "images_dir = os.path.join(paths['processed_path'], 'images')\n",
    "display_images_with_captions(captions_df, images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Caption Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize captions\n",
    "# TODO: Implement the tokenize function for caption text\n",
    "# This function should:\n",
    "# 1. Convert text to lowercase\n",
    "# 2. Remove punctuation using regex\n",
    "# 3. Split text into tokens using NLTK's word_tokenize\n",
    "# 4. Return the list of tokens\n",
    "def tokenize(text):\n",
    "    # Your implementation here\n",
    "    tokens = list()\n",
    "    return tokens\n",
    "\n",
    "# Calculate caption lengths\n",
    "captions_df['tokens'] = captions_df['caption'].apply(tokenize)\n",
    "captions_df['length'] = captions_df['tokens'].apply(len)\n",
    "\n",
    "# Display statistics\n",
    "caption_lengths = captions_df['length']\n",
    "print(f\"Min length: {caption_lengths.min()}\")\n",
    "print(f\"Max length: {caption_lengths.max()}\")\n",
    "print(f\"Mean length: {caption_lengths.mean():.2f}\")\n",
    "print(f\"Median length: {caption_lengths.median()}\")\n",
    "print(f\"90th percentile length: {caption_lengths.quantile(0.9)}\")\n",
    "print(f\"95th percentile length: {caption_lengths.quantile(0.95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of caption lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(caption_lengths, bins=20, kde=True)\n",
    "plt.axvline(x=caption_lengths.mean(), color='r', linestyle='--', label=f'Mean: {caption_lengths.mean():.2f}')\n",
    "plt.axvline(x=caption_lengths.median(), color='g', linestyle='--', label=f'Median: {caption_lengths.median()}')\n",
    "plt.axvline(x=caption_lengths.quantile(0.95), color='b', linestyle='--', label=f'95th percentile: {caption_lengths.quantile(0.95)}')\n",
    "plt.title('Distribution of Caption Lengths')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Examine the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count word frequencies\n",
    "all_tokens = [token for tokens in captions_df['tokens'] for token in tokens]\n",
    "word_freq = Counter(all_tokens)\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Total vocabulary size: {len(word_freq)}\")\n",
    "print(f\"Number of words appearing only once: {sum(1 for count in word_freq.values() if count == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the most common words\n",
    "top_n = 30\n",
    "most_common = word_freq.most_common(top_n)\n",
    "words, counts = zip(*most_common)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=list(counts), y=list(words))\n",
    "plt.title(f'Top {top_n} Most Common Words')\n",
    "plt.xlabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate vocabulary coverage with different frequency thresholds\n",
    "# TODO: Calculate vocabulary coverage for different word frequency thresholds\n",
    "# For each threshold:\n",
    "# 1. Find words that appear at least 'threshold' times\n",
    "# 2. Calculate vocabulary size (number of unique words above threshold)\n",
    "# 3. Calculate what percentage of all tokens are covered by this vocabulary\n",
    "# 4. Store results for plotting\n",
    "thresholds = [1, 2, 3, 5, 10]\n",
    "coverage = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Your implementation here\n",
    "    vocab_size = ...\n",
    "    coverage_pct = ...\n",
    "    print(f\"Threshold: {threshold}, Vocabulary size: {vocab_size}, Coverage: {coverage_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vocabulary coverage\n",
    "thresholds, vocab_sizes, coverages = zip(*coverage)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot vocabulary size\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Frequency Threshold')\n",
    "ax1.set_ylabel('Vocabulary Size', color=color)\n",
    "ax1.plot(thresholds, vocab_sizes, 'o-', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Create second y-axis for coverage\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Coverage (%)', color=color)\n",
    "ax2.plot(thresholds, coverages, 's-', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Vocabulary Size and Coverage vs. Frequency Threshold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build and Save the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and save the vocabulary\n",
    "freq_threshold = 5  # Words appearing less than 5 times are considered rare\n",
    "vocab = build_vocab_from_captions(captions_path, paths['processed_path'], freq_threshold=freq_threshold)\n",
    "\n",
    "print(f\"Built vocabulary with {len(vocab)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explore Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data splits\n",
    "train_df = pd.read_csv(os.path.join(paths['processed_path'], 'train_captions.csv'))\n",
    "val_df = pd.read_csv(os.path.join(paths['processed_path'], 'val_captions.csv'))\n",
    "test_df = pd.read_csv(os.path.join(paths['processed_path'], 'test_captions.csv'))\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Training set: {train_df['image'].nunique()} images, {len(train_df)} captions\")\n",
    "print(f\"Validation set: {val_df['image'].nunique()} images, {len(val_df)} captions\")\n",
    "print(f\"Test set: {test_df['image'].nunique()} images, {len(test_df)} captions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image dimensions for a sample of images\n",
    "# TODO: Implement a function to analyze image dimensions in the dataset\n",
    "# This function should:\n",
    "# 1. Get a sample of image files from the directory\n",
    "# 2. Load each image and extract its dimensions\n",
    "# 3. Return a DataFrame with width and height columns for analysis\n",
    "def check_image_dimensions(images_dir, num_samples=100):\n",
    "    # Your implementation here\n",
    "    dim_df = ...\n",
    "    return dim_df\n",
    "\n",
    "# Check dimensions\n",
    "image_dimensions = check_image_dimensions(images_dir)\n",
    "\n",
    "# Display statistics\n",
    "print(\"Image dimension statistics:\")\n",
    "print(image_dimensions.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image dimensions\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(image_dimensions['width'], image_dimensions['height'], alpha=0.5)\n",
    "plt.title('Image Dimensions')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Height (pixels)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have explored the Flickr8k dataset for image captioning. We have:\n",
    "\n",
    "1. Downloaded and prepared the dataset\n",
    "2. Explored the images and captions\n",
    "3. Analyzed the distribution of caption lengths\n",
    "4. Examined the vocabulary and its coverage\n",
    "5. Built and saved the vocabulary\n",
    "6. Explored the data splits\n",
    "7. Checked image dimensions\n",
    "\n",
    "This exploration gives us a good understanding of the dataset and helps us make informed decisions when designing our image captioning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
